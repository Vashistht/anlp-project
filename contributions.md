# Contributions

## Vashisth (vashistt)
- Initial survey on small model reasoning, pruning methods that perform well on complex tasks
- Code
  - Ran Bonsai code from the paper
  - Made necessary edits to run the code on the given compute limitations
  - Ran pruning code for Llama, Sheared Llama 2.7
  - Experimented with other models including Phi, TinyLLama  
  - Ran evals to recreate the metrics given in the dataset
  - Identified errors in the code + added git issues to the source code
-  Report:
  - Implementation & Deviations, Results, Proposal sections

## Amanda (xal)
- Conducted initial literature survey on our topic of interest: multilingual, small model reasoning, pruning, etc
- Written various parts of the report
  - literature review of Bonsai, Gradient-Free Structured Pruning, Prompt2Model
  - Summarization
  - Discussion and Proposal
- Light work on implementation specifics, including initial setup and runthrough of smaller LlaMa models with Bonsai

## Emily
